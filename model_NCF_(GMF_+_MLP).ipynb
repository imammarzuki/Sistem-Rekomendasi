{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rzZrFtCzxPe3",
        "outputId": "2744f9b3-c4bc-4797-90b2-08836e8889c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "464/464 [==============================] - 3s 3ms/step - loss: 0.6782 - val_loss: 0.4019\n",
            "Epoch 2/100\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.3551 - val_loss: 0.4149\n",
            "Epoch 3/100\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.3144 - val_loss: 0.4218\n",
            "Epoch 4/100\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2908 - val_loss: 0.4269\n",
            "Epoch 5/100\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2796 - val_loss: 0.4847\n",
            "Epoch 6/100\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2506 - val_loss: 0.4766\n",
            "Epoch 7/100\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2232 - val_loss: 0.5048\n",
            "Epoch 8/100\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.1895 - val_loss: 0.5397\n",
            "Epoch 9/100\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.1553 - val_loss: 0.5419\n",
            "Epoch 10/100\n",
            "464/464 [==============================] - 2s 4ms/step - loss: 0.1231 - val_loss: 0.5828\n",
            "Epoch 11/100\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.1000 - val_loss: 0.6463\n",
            "Epoch 12/100\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.0788 - val_loss: 0.6285\n",
            "Epoch 13/100\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.0684 - val_loss: 0.6385\n",
            "Epoch 14/100\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.0510 - val_loss: 0.6687\n",
            "Epoch 15/100\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.0407 - val_loss: 0.6107\n",
            "Epoch 16/100\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.0373 - val_loss: 0.5989\n",
            "Epoch 17/100\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.0300 - val_loss: 0.6344\n",
            "Epoch 18/100\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.0308 - val_loss: 0.6357\n",
            "Epoch 19/100\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.0299 - val_loss: 0.6326\n",
            "Epoch 20/100\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.0297 - val_loss: 0.6562\n",
            "Epoch 21/100\n",
            "464/464 [==============================] - 2s 4ms/step - loss: 0.0249 - val_loss: 0.6102\n",
            "Epoch 22/100\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.0244 - val_loss: 0.6492\n",
            "Epoch 23/100\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.0195 - val_loss: 0.6671\n",
            "Epoch 24/100\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.0190 - val_loss: 0.6474\n",
            "Epoch 25/100\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.0237 - val_loss: 0.6260\n",
            "Epoch 26/100\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.0209 - val_loss: 0.6269\n",
            "Epoch 27/100\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.0204 - val_loss: 0.6507\n",
            "Epoch 28/100\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.0201 - val_loss: 0.6272\n",
            "Epoch 29/100\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.0174 - val_loss: 0.6521\n",
            "Epoch 30/100\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.0174 - val_loss: 0.6291\n",
            "Epoch 31/100\n",
            "464/464 [==============================] - 2s 4ms/step - loss: 0.0187 - val_loss: 0.6753\n",
            "Epoch 32/100\n",
            "464/464 [==============================] - 2s 4ms/step - loss: 0.0183 - val_loss: 0.6358\n",
            "Epoch 33/100\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.0164 - val_loss: 0.6945\n",
            "Epoch 34/100\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.0147 - val_loss: 0.5806\n",
            "Epoch 35/100\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.0149 - val_loss: 0.6783\n",
            "Epoch 36/100\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.0153 - val_loss: 0.6174\n",
            "Epoch 37/100\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.0151 - val_loss: 0.6730\n",
            "Epoch 38/100\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.0140 - val_loss: 0.5979\n",
            "Epoch 39/100\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.0137 - val_loss: 0.6402\n",
            "Epoch 40/100\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.0149 - val_loss: 0.6322\n",
            "Epoch 41/100\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.0157 - val_loss: 0.6289\n",
            "Epoch 42/100\n",
            "464/464 [==============================] - 2s 4ms/step - loss: 0.0147 - val_loss: 0.6129\n",
            "Epoch 43/100\n",
            "464/464 [==============================] - 2s 3ms/step - loss: 0.0142 - val_loss: 0.6452\n",
            "Epoch 44/100\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.0133 - val_loss: 0.6252\n",
            "Epoch 45/100\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.0117 - val_loss: 0.6006\n",
            "Epoch 46/100\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.0108 - val_loss: 0.6017\n",
            "Epoch 47/100\n",
            "464/464 [==============================] - 2s 5ms/step - loss: 0.0127 - val_loss: 0.6227\n",
            "Epoch 48/100\n",
            "464/464 [==============================] - 2s 5ms/step - loss: 0.0127 - val_loss: 0.6080\n",
            "Epoch 49/100\n",
            "464/464 [==============================] - 4s 8ms/step - loss: 0.0118 - val_loss: 0.6228\n",
            "Epoch 50/100\n",
            "464/464 [==============================] - 2s 4ms/step - loss: 0.0116 - val_loss: 0.6064\n",
            "Epoch 51/100\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.0106 - val_loss: 0.6234\n",
            "Epoch 52/100\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.0112 - val_loss: 0.6286\n",
            "Epoch 53/100\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.0102 - val_loss: 0.6236\n",
            "Epoch 54/100\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.0108 - val_loss: 0.6572\n",
            "Epoch 55/100\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.0098 - val_loss: 0.6240\n",
            "Epoch 56/100\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.0116 - val_loss: 0.6125\n",
            "Epoch 57/100\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.0100 - val_loss: 0.6131\n",
            "Epoch 58/100\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.0102 - val_loss: 0.5873\n",
            "Epoch 59/100\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.0103 - val_loss: 0.6527\n",
            "Epoch 60/100\n",
            "464/464 [==============================] - 2s 4ms/step - loss: 0.0121 - val_loss: 0.6016\n",
            "Epoch 61/100\n",
            "464/464 [==============================] - 2s 4ms/step - loss: 0.0109 - val_loss: 0.6410\n",
            "Epoch 62/100\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.0084 - val_loss: 0.6323\n",
            "Epoch 63/100\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.0082 - val_loss: 0.5986\n",
            "Epoch 64/100\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.0088 - val_loss: 0.6233\n",
            "Epoch 65/100\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.0101 - val_loss: 0.6295\n",
            "Epoch 66/100\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.0087 - val_loss: 0.5951\n",
            "Epoch 67/100\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.0087 - val_loss: 0.6603\n",
            "Epoch 68/100\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.0091 - val_loss: 0.6165\n",
            "Epoch 69/100\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.0101 - val_loss: 0.6374\n",
            "Epoch 70/100\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.0087 - val_loss: 0.6051\n",
            "Epoch 71/100\n",
            "464/464 [==============================] - 2s 4ms/step - loss: 0.0085 - val_loss: 0.6239\n",
            "Epoch 72/100\n",
            "464/464 [==============================] - 2s 3ms/step - loss: 0.0079 - val_loss: 0.5900\n",
            "Epoch 73/100\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.0083 - val_loss: 0.6136\n",
            "Epoch 74/100\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.0071 - val_loss: 0.5973\n",
            "Epoch 75/100\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.0075 - val_loss: 0.6332\n",
            "Epoch 76/100\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.0076 - val_loss: 0.6235\n",
            "Epoch 77/100\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.0081 - val_loss: 0.6248\n",
            "Epoch 78/100\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.0080 - val_loss: 0.6149\n",
            "Epoch 79/100\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.0079 - val_loss: 0.6030\n",
            "Epoch 80/100\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.0078 - val_loss: 0.6192\n",
            "Epoch 81/100\n",
            "464/464 [==============================] - 2s 3ms/step - loss: 0.0077 - val_loss: 0.6298\n",
            "Epoch 82/100\n",
            "464/464 [==============================] - 2s 4ms/step - loss: 0.0073 - val_loss: 0.6283\n",
            "Epoch 83/100\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.0061 - val_loss: 0.6204\n",
            "Epoch 84/100\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.0065 - val_loss: 0.6238\n",
            "Epoch 85/100\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.0077 - val_loss: 0.6317\n",
            "Epoch 86/100\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.0079 - val_loss: 0.6098\n",
            "Epoch 87/100\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.0072 - val_loss: 0.6013\n",
            "Epoch 88/100\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.0078 - val_loss: 0.6309\n",
            "Epoch 89/100\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.0062 - val_loss: 0.6116\n",
            "Epoch 90/100\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.0070 - val_loss: 0.5894\n",
            "Epoch 91/100\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.0072 - val_loss: 0.6288\n",
            "Epoch 92/100\n",
            "464/464 [==============================] - 2s 5ms/step - loss: 0.0080 - val_loss: 0.6116\n",
            "Epoch 93/100\n",
            "464/464 [==============================] - 2s 4ms/step - loss: 0.0061 - val_loss: 0.6147\n",
            "Epoch 94/100\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.0062 - val_loss: 0.5862\n",
            "Epoch 95/100\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.0058 - val_loss: 0.6004\n",
            "Epoch 96/100\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.0063 - val_loss: 0.6093\n",
            "Epoch 97/100\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.0070 - val_loss: 0.5838\n",
            "Epoch 98/100\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.0067 - val_loss: 0.6059\n",
            "Epoch 99/100\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.0062 - val_loss: 0.6286\n",
            "Epoch 100/100\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.0068 - val_loss: 0.6074\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7e590e2552d0>"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Embedding, Flatten, Concatenate, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import MeanSquaredError\n",
        "\n",
        "# Misal kita punya DataFrame dengan kolom 'user_id', 'item_id', dan 'rating'\n",
        "# Sesuaikan dataset Anda dengan kolom yang sesuai\n",
        "\n",
        "df = pd.read_csv('rating_final.csv')\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Contoh pemetaan untuk user_id\n",
        "user_encoder = LabelEncoder()\n",
        "df['userID'] = user_encoder.fit_transform(df['userID'])\n",
        "\n",
        "# Pemetaan untuk item_id\n",
        "item_encoder = LabelEncoder()\n",
        "df['placeID'] = item_encoder.fit_transform(df['placeID'])\n",
        "\n",
        "# Split data menjadi data latih dan validasi\n",
        "train_data, val_data = train_test_split(df, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Jumlah pengguna dan item\n",
        "num_users = df['userID'].nunique()\n",
        "num_items = df['placeID'].nunique()\n",
        "\n",
        "# Menentukan ukuran embedding\n",
        "embedding_size = 50\n",
        "\n",
        "# Input layer\n",
        "user_input = Input(shape=(1,), name='user_input')\n",
        "item_input = Input(shape=(1,), name='item_input')\n",
        "\n",
        "# Embedding layer for GCF\n",
        "user_embedding = Embedding(input_dim=num_users, output_dim=embedding_size, input_length=1)(user_input)\n",
        "item_embedding = Embedding(input_dim=num_items, output_dim=embedding_size, input_length=1)(item_input)\n",
        "\n",
        "# Flatten embeddings\n",
        "user_flat = Flatten()(user_embedding)\n",
        "item_flat = Flatten()(item_embedding)\n",
        "\n",
        "# Concatenate embeddings for GCF\n",
        "concatenated_gcf = Concatenate()([user_flat, item_flat])\n",
        "\n",
        "# Multi-Layer Perceptron (MLP)\n",
        "mlp_input = Concatenate()([user_embedding, item_embedding])\n",
        "mlp_flatten = Flatten()(mlp_input)\n",
        "mlp_fc1 = Dense(64, activation='relu')(mlp_flatten)\n",
        "mlp_output = Dense(1)(mlp_fc1)\n",
        "\n",
        "# Combine GCF and MLP outputs\n",
        "combined = Concatenate()([concatenated_gcf, mlp_output])\n",
        "\n",
        "# Fully connected layers for final prediction\n",
        "final_fc1 = Dense(64, activation='relu')(combined)\n",
        "output = Dense(1)(final_fc1)\n",
        "\n",
        "# Model\n",
        "model = Model(inputs=[user_input, item_input], outputs=output)\n",
        "\n",
        "# Compile model\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss=MeanSquaredError())\n",
        "\n",
        "# Training model\n",
        "model.fit([train_data['userID'], train_data['placeID']], train_data['rating'], epochs=100, batch_size=2, validation_data=([val_data['userID'], val_data['placeID']], val_data['rating']))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}